[core]
no_lock = True

[worker]
keep_alive = False
ping_interval = 20
wait_interval = 20
max_reschedules = 0

[DEFAULT]
name = MC_Test

; grid storage protocol and path usable from submitting machine and worker nodes of cluster
; job in- and output will be stored in $wlcg_path under subdirectory of analysis $name
wlcg_path = srm://cmssrm-kit.gridka.de:8443/srm/managerv2?SFN=/pnfs/gridka.de/cms/disk-only/store/user/mhorzela/HerwigMC
;wlcg_path = srm://grid-srm.physik.rwth-aachen.de:8443/srm/managerv2?SFN=/pnfs/physik.rwth-aachen.de/cms/store/user/mhorzela/HerwigMC
xrootd_path = root://cmsxrootd-redirectors.gridka.de//store/user/mhorzela/NP_Corrections/MC_Production

; default htcondor job submission configuration (modifiable for each task)
htcondor_accounting_group = cms.jet
htcondor_remote_job = True
; TODO: Set your user proxy to your personal one 
htcondor_user_proxy = /tmp/x509up_u12249
htcondor_request_cpus = 1
; for all cores in total
htcondor_universe = docker
htcondor_docker_image = mschnepf/slc7-condocker
; create log files in htcondor jobs
transfer_logs = True
; set local scheduler
local_scheduler = True
; set tolerance for workflow success with failed branches
tolerance = 0.00
acceptance = 1.00
; submit only missing htcondor workflow branches (should always be true)
only_missing = True

; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_lawherwig.sh

; general Herwig parameters
; Herwig input file and settings
; the name of the input file in the inputfiles directory w/o file extension
input_file_name = LHC-LO-Z2JetMerging
; currently only for grid storage path
mc_setting = test




[HerwigBuild]
; directory name to search for Herwig steering file
config_path = default


[HerwigIntegrate]
; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_lawherwig.sh
; number of integration jobs
integration_maxjobs = 30
;HTCondor
htcondor_walltime = 3600
htcondor_request_memory = 2500
htcondor_requirements = TARGET.ProvidesCPU
htcondor_request_disk = 2000000


[HerwigMerge]


[HerwigRun]
; Herwig setupfile for additional confgurations
setupfile = None
; run specific settings
number_of_jobs = 4000
events_per_job = 10000
; start seed for random seed generation, per default turned off
start_seed = 100
; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_lawherwig.sh
; HTCondor
htcondor_walltime = 10800
htcondor_request_memory = 2500
htcondor_requirements = TARGET.ProvidesCPU
htcondor_request_disk = 2000000


[RunRivet]
; number of analyzed files per job = number_of_jobs/rivet_jobs
files_per_job = 10
; analyses to run on generated HepMC files
; make sure that you have your plugin analyses in ./generation/analyses included
rivet_analyses = ["ZplusJet_3","MC_ZINC_MU","MC_ZJETS_MU","MC_XS","MC_WEIGHTS"]
; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_lawrivet.sh
; HTCondor
htcondor_walltime = 3600
htcondor_request_memory = 2500
htcondor_requirements = TARGET.ProvidesIO
htcondor_request_disk = 20000000


[RivetMerge]
; number of files per rivetmerge chunk
chunk_size = 300


[ConvertYodaToRoot]


[PalisadeNPCorr]
; MC campaigns to plot NP-Corr plots for
input_file_names = []
; names of the mc_setting for full production and turned-off non-perturbative part
mc_setting_full = "withNP"
mc_setting_NPoff = "NPoff"
